{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed data parallel MNIST training with PyTorch and SMDataParallel\n",
    "\n",
    "\n",
    "## Background\n",
    "SMDataParallel is a new capability in Amazon SageMaker to train deep learning models faster and cheaper. SMDataParallel is a distributed data parallel training framework for PyTorch. \n",
    "\n",
    "This notebook example shows how to use SMDataParallel with PyTorch in SageMaker using MNIST dataset.\n",
    "\n",
    "For more information:\n",
    "1. [PyTorch in SageMaker](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html)\n",
    "2. [SMDataParallel PyTorch API Specification] < LINK TO BE ADDED >\n",
    "3. [Getting started with SMDataParallel on SageMaker] < LINK TO BE ADDED >\n",
    "\n",
    "**NOTE:** This example requires SageMaker Python SDK v2.X.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "This example uses the MNIST dataset. MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker execution roles\n",
    "\n",
    "The IAM role arn used to give training and hosting access to your data. See the [Amazon SageMaker Roles](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.19.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.23.4.post0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.16.37)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (20.7)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (1.19.4)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (3.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (3.1.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.19.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.32->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.37->boto3>=1.16.32->sagemaker) (1.25.11)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker) (3.14.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.37 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.19.37)\n",
      "Collecting smdebug-rulesconfig==1.0.1\n",
      "  Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Installing collected packages: smdebug-rulesconfig, sagemaker\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.0\n",
      "    Uninstalling smdebug-rulesconfig-1.0.0:\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.19.0\n",
      "    Uninstalling sagemaker-2.19.0:\n",
      "      Successfully uninstalled sagemaker-2.19.0\n",
      "Successfully installed sagemaker-2.23.4.post0 smdebug-rulesconfig-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training with SMDataParallel\n",
    "\n",
    "### Training script\n",
    "\n",
    "The MNIST dataset is downloaded using the `torchvision.datasets` PyTorch module; you can see how this is implemented in the `train_pytorch_smdataparallel_mnist.py` training script that is printed out in the next cell.\n",
    "\n",
    "The training script provides the code you need for distributed data parallel (DDP) training using SMDataParallel. The training script is very similar to a PyTorch training script you might run outside of SageMaker, but modified to run with SMDataParallel. SMDataParallel's PyTorch client provides an alternative to PyTorch's native DDP. For details about how to use SMDataParallel's DDP in your native PyTorch script, see the Getting Started with SMDataParallel tutorials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\r\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\r\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\r\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\r\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\r\n",
      "\u001b[37m# language governing permissions and limitations under the License.\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlr_scheduler\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StepLR\r\n",
      "\r\n",
      "\u001b[37m# Network definition\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel_def\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Net\r\n",
      "\r\n",
      "\u001b[37m# Import SMDataParallel PyTorch Modules\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msmdistributed\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdataparallel\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mparallel\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DistributedDataParallel \u001b[34mas\u001b[39;49;00m DDP\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msmdistributed\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdataparallel\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\r\n",
      "\r\n",
      "dist.init_process_group()\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args, model, device, train_loader, optimizer, epoch):\r\n",
      "    model.train()\r\n",
      "    \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader):\r\n",
      "        data, target = data.to(device), target.to(device)\r\n",
      "        optimizer.zero_grad()\r\n",
      "        output = model(data)\r\n",
      "        loss = F.nll_loss(output, target)\r\n",
      "        loss.backward()\r\n",
      "        optimizer.step()\r\n",
      "        \u001b[34mif\u001b[39;49;00m batch_idx % args.log_interval == \u001b[34m0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.rank == \u001b[34m0\u001b[39;49;00m:\r\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)]\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mLoss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\r\n",
      "                epoch, batch_idx * \u001b[36mlen\u001b[39;49;00m(data) * args.world_size, \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\r\n",
      "                \u001b[34m100.\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader), loss.item()))\r\n",
      "        \u001b[34mif\u001b[39;49;00m args.verbose:\r\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mBatch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, batch_idx, \u001b[33m\"\u001b[39;49;00m\u001b[33mfrom rank\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, args.rank)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, device, test_loader):\r\n",
      "    model.eval()\r\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\r\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\r\n",
      "        \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m test_loader:\r\n",
      "            data, target = data.to(device), target.to(device)\r\n",
      "            output = model(data)\r\n",
      "            test_loss += F.nll_loss(output, target, reduction=\u001b[33m'\u001b[39;49;00m\u001b[33msum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\r\n",
      "            pred = output.argmax(dim=\u001b[34m1\u001b[39;49;00m, keepdim=\u001b[34mTrue\u001b[39;49;00m)  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\r\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\r\n",
      "\r\n",
      "    test_loss /= \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\r\n",
      "\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mTest set: Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\r\n",
      "        test_loss, correct, \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\r\n",
      "        \u001b[34m100.\u001b[39;49;00m * correct / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        torch.save(model.module.state_dict(), f)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\r\n",
      "    \u001b[37m# Training settings\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser(description=\u001b[33m'\u001b[39;49;00m\u001b[33mPyTorch MNIST Example\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1000\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m14\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 14)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m1.0\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 1.0)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--gamma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.7\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mLearning rate step gamma (default: 0.7)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--save-model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, action=\u001b[33m'\u001b[39;49;00m\u001b[33mstore_true\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, default=\u001b[34mFalse\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mFor Saving the current Model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--verbose\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, action=\u001b[33m'\u001b[39;49;00m\u001b[33mstore_true\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, default=\u001b[34mFalse\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mFor displaying SMDataParallel-specific logs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-path\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33m/tmp/data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mPath for downloading \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "                                                                           \u001b[33m'\u001b[39;49;00m\u001b[33mthe MNIST dataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[37m# Model checkpoint location\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    args = parser.parse_args()\r\n",
      "    args.world_size = dist.get_world_size()\r\n",
      "    args.rank = rank = dist.get_rank()\r\n",
      "    args.local_rank = local_rank = dist.get_local_rank()\r\n",
      "    args.lr = \u001b[34m1.0\u001b[39;49;00m\r\n",
      "    args.batch_size //= args.world_size // \u001b[34m8\u001b[39;49;00m\r\n",
      "    args.batch_size = \u001b[36mmax\u001b[39;49;00m(args.batch_size, \u001b[34m1\u001b[39;49;00m)\r\n",
      "    data_path = args.data_path\r\n",
      "\r\n",
      "                        \r\n",
      "    \u001b[34mif\u001b[39;49;00m args.verbose:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mHello from rank\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, rank, \u001b[33m'\u001b[39;49;00m\u001b[33mof local_rank\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                local_rank, \u001b[33m'\u001b[39;49;00m\u001b[33min world size of\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, args.world_size)\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m torch.cuda.is_available():\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mMust run SMDataParallel MNIST example on CUDA-capable devices.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    torch.manual_seed(args.seed)\r\n",
      "\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m local_rank == \u001b[34m0\u001b[39;49;00m:\r\n",
      "        train_dataset = datasets.MNIST(data_path, train=\u001b[34mTrue\u001b[39;49;00m, download=\u001b[34mTrue\u001b[39;49;00m,\r\n",
      "                       transform=transforms.Compose([\r\n",
      "                           transforms.ToTensor(),\r\n",
      "                           transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))\r\n",
      "                       ]))\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        time.sleep(\u001b[34m8\u001b[39;49;00m)\r\n",
      "        train_dataset = datasets.MNIST(data_path, train=\u001b[34mTrue\u001b[39;49;00m, download=\u001b[34mFalse\u001b[39;49;00m,\r\n",
      "                       transform=transforms.Compose([\r\n",
      "                           transforms.ToTensor(),\r\n",
      "                           transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))\r\n",
      "                       ]))\r\n",
      "\r\n",
      "    train_sampler = torch.utils.data.distributed.DistributedSampler(\r\n",
      "            train_dataset,\r\n",
      "            num_replicas=args.world_size,\r\n",
      "            rank=rank)\r\n",
      "    train_loader = torch.utils.data.DataLoader(\r\n",
      "        train_dataset,\r\n",
      "        batch_size=args.batch_size,\r\n",
      "        shuffle=\u001b[34mFalse\u001b[39;49;00m,\r\n",
      "        num_workers=\u001b[34m0\u001b[39;49;00m,\r\n",
      "        pin_memory=\u001b[34mTrue\u001b[39;49;00m,\r\n",
      "        sampler=train_sampler)\r\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\r\n",
      "        test_loader = torch.utils.data.DataLoader(\r\n",
      "            datasets.MNIST(data_path, train=\u001b[34mFalse\u001b[39;49;00m, transform=transforms.Compose([\r\n",
      "                               transforms.ToTensor(),\r\n",
      "                               transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))\r\n",
      "                           ])),\r\n",
      "            batch_size=args.test_batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# Use SMDataParallel PyTorch DDP for efficient distributed training\u001b[39;49;00m\r\n",
      "    model = DDP(Net().to(device))\r\n",
      "    torch.cuda.set_device(local_rank)\r\n",
      "    model.cuda(local_rank)\r\n",
      "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\r\n",
      "    scheduler = StepLR(optimizer, step_size=\u001b[34m1\u001b[39;49;00m, gamma=args.gamma)\r\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\r\n",
      "        train(args, model, device, train_loader, optimizer, epoch)\r\n",
      "        \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\r\n",
      "            test(model, device, test_loader)\r\n",
      "        scheduler.step()\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "        save_model(model, args.model_dir)   \r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    main()\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/train_pytorch_smdataparallel_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator function options\n",
    "\n",
    "In the following code block, you can update the estimator function to use a different instance type, instance count, and distrubtion strategy. You're also passing in the training script you reviewed in the previous cell.\n",
    "\n",
    "**Instance types**\n",
    "\n",
    "SMDataParallel supports model training on SageMaker with the following instance types only:\n",
    "1. ml.p3.16xlarge\n",
    "1. ml.p3dn.24xlarge [Recommended]\n",
    "1. ml.p4d.24xlarge [Recommended]\n",
    "\n",
    "**Instance count**\n",
    "\n",
    "To get the best performance and the most out of SMDataParallel, you should use at least 2 instances, but you can also use 1 for testing this example.\n",
    "\n",
    "**Distribution strategy**\n",
    "\n",
    "Note that to use DDP mode, you update the the `distribution` strategy, and set it to use `smdistributed dataparallel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "estimator = PyTorch(base_job_name='pytorch-smdataparallel-mnist',\n",
    "                        source_dir='code',\n",
    "                        entry_point='train_pytorch_smdataparallel_mnist.py',\n",
    "                        role=role,\n",
    "                        framework_version='1.6.0',\n",
    "                        py_version='py36',\n",
    "                        # For training with multinode distributed training, set this count. Example: 2\n",
    "                        instance_count=2,\n",
    "                        # For training with p3dn instance use - ml.p3dn.24xlarge\n",
    "                        instance_type= 'ml.p3.16xlarge',\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        # Training using SMDataParallel Distributed Training Framework\n",
    "                        distribution={'smdistributed':{\n",
    "                                            'dataparallel':{\n",
    "                                                    'enabled': True\n",
    "                                                 }\n",
    "                                          }\n",
    "                                      },\n",
    "                        debugger_hook_config=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-18 04:48:36 Starting - Starting the training job...\n",
      "2021-01-18 04:49:00 Starting - Launching requested ML instancesProfilerReport-1610945316: InProgress\n",
      ".........\n",
      "2021-01-18 04:50:21 Starting - Preparing the instances for training.........\n",
      "2021-01-18 04:52:07 Downloading - Downloading input data...\n",
      "2021-01-18 04:52:22 Training - Downloading the training image..............\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:41,915 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:41,993 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:44,917 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:44,996 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,027 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,027 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,226 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,226 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,534 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,534 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,537 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,538 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,538 sagemaker-training-toolkit ERROR    Connection failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_training/smdataparallel.py\", line 303, in _can_connect\n",
      "    client.connect(host, port=port)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/paramiko/client.py\", line 368, in connect\n",
      "    raise NoValidConnectionsError(errors)\u001b[0m\n",
      "\u001b[34mparamiko.ssh_exception.NoValidConnectionsError: [Errno None] Unable to connect to port 22 on 10.0.199.171\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:48,540 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,701 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,701 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,709 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,782 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,783 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,783 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,783 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:48,787 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,549 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,622 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,622 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,622 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,622 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,622 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,622 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,623 sagemaker-training-toolkit INFO     instance type: ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34m2021-01-18 04:54:49,702 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-smdataparallel-mnist-2021-01-18-04-48-35-964\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-230755935769/pytorch-smdataparallel-mnist-2021-01-18-04-48-35-964/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_pytorch_smdataparallel_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_pytorch_smdataparallel_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_pytorch_smdataparallel_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_pytorch_smdataparallel_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-230755935769/pytorch-smdataparallel-mnist-2021-01-18-04-48-35-964/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-smdataparallel-mnist-2021-01-18-04-48-35-964\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-230755935769/pytorch-smdataparallel-mnist-2021-01-18-04-48-35-964/source/sourcedir.tar.gz\",\"module_name\":\"train_pytorch_smdataparallel_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_pytorch_smdataparallel_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=sockets -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p3.16xlarge smddprun /opt/conda/bin/python -m mpi4py train_pytorch_smdataparallel_mnist.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:50,793 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=49, name='orted', status='running', started='04:54:49')]\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:50,793 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=49, name='orted', status='running', started='04:54:49')]\u001b[0m\n",
      "\u001b[35m2021-01-18 04:54:50,793 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=49, name='orted', status='running', started='04:54:49')]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-01-18 04:55:04 Training - Training image download completed. Training in progress.\u001b[34m[1,8]<stdout>:NCCL version 2.7.8+cuda11.0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.7.8+cuda11.0\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Running smdistributed.dataparallel v1.0.0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Extracting /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Extracting /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Extracting /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Extracting /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Extracting /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Extracting /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Extracting /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Processing...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Done!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Extracting /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Processing...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-18 04:55:08.035 algo-1:49 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-01-18 04:55:08.035 algo-1:51 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-01-18 04:55:08.035 algo-1:60 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-01-18 04:55:08.036 algo-1:59 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-01-18 04:55:08.042 algo-1:61 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-01-18 04:55:08.044 algo-1:57 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-01-18 04:55:08.046 algo-2:67 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-01-18 04:55:08.046 algo-2:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-01-18 04:55:08.046 algo-2:60 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-01-18 04:55:08.046 algo-2:62 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-01-18 04:55:08.047 algo-2:66 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-01-18 04:55:08.048 algo-2:56 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-01-18 04:55:08.050 algo-2:64 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-01-18 04:55:08.048 algo-1:55 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-01-18 04:55:08.049 algo-1:53 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-01-18 04:55:08.073 algo-2:58 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-01-18 04:55:08.438 algo-1:49 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-01-18 04:55:08.440 algo-1:51 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-01-18 04:55:08.440 algo-1:59 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-01-18 04:55:08.441 algo-1:60 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-01-18 04:55:08.442 algo-1:55 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-01-18 04:55:08.442 algo-1:61 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-01-18 04:55:08.443 algo-1:57 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-01-18 04:55:08.444 algo-1:53 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-01-18 04:55:08.456 algo-2:56 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-01-18 04:55:08.458 algo-2:58 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-01-18 04:55:08.460 algo-2:68 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-01-18 04:55:08.460 algo-2:62 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-01-18 04:55:08.460 algo-2:66 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-01-18 04:55:08.461 algo-2:64 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-01-18 04:55:08.461 algo-2:67 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-01-18 04:55:08.492 algo-2:60 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [0/60000 (0%)]#011Loss: 2.344856\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [5120/60000 (8%)]#011Loss: 1.274764\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [10240/60000 (17%)]#011Loss: 0.564119\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [15360/60000 (25%)]#011Loss: 0.442943\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [20480/60000 (34%)]#011Loss: 0.292081\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [25600/60000 (42%)]#011Loss: 0.289782\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [30720/60000 (51%)]#011Loss: 0.179676\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [35840/60000 (59%)]#011Loss: 0.085267\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [40960/60000 (68%)]#011Loss: 0.088424\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [46080/60000 (76%)]#011Loss: 0.069336\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [51200/60000 (85%)]#011Loss: 0.228843\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 1 [56320/60000 (93%)]#011Loss: 0.257070\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0889, Accuracy: 9721/10000 (97%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [0/60000 (0%)]#011Loss: 0.158783\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [5120/60000 (8%)]#011Loss: 0.309680\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [10240/60000 (17%)]#011Loss: 0.094504\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [15360/60000 (25%)]#011Loss: 0.160828\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [20480/60000 (34%)]#011Loss: 0.188864\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [25600/60000 (42%)]#011Loss: 0.198770\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [30720/60000 (51%)]#011Loss: 0.066052\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [35840/60000 (59%)]#011Loss: 0.021108\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [40960/60000 (68%)]#011Loss: 0.114088\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [46080/60000 (76%)]#011Loss: 0.088980\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [51200/60000 (85%)]#011Loss: 0.157899\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 2 [56320/60000 (93%)]#011Loss: 0.039667\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0624, Accuracy: 9793/10000 (98%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [0/60000 (0%)]#011Loss: 0.034911\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [5120/60000 (8%)]#011Loss: 0.174399\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [10240/60000 (17%)]#011Loss: 0.368446\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [15360/60000 (25%)]#011Loss: 0.292473\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [20480/60000 (34%)]#011Loss: 0.106532\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [25600/60000 (42%)]#011Loss: 0.106666\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [30720/60000 (51%)]#011Loss: 0.078508\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [35840/60000 (59%)]#011Loss: 0.026328\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [40960/60000 (68%)]#011Loss: 0.172945\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [46080/60000 (76%)]#011Loss: 0.040606\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [51200/60000 (85%)]#011Loss: 0.136408\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 3 [56320/60000 (93%)]#011Loss: 0.168302\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0533, Accuracy: 9826/10000 (98%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [0/60000 (0%)]#011Loss: 0.185982\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [5120/60000 (8%)]#011Loss: 0.191980\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [10240/60000 (17%)]#011Loss: 0.180701\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [15360/60000 (25%)]#011Loss: 0.074552\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [20480/60000 (34%)]#011Loss: 0.213500\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [25600/60000 (42%)]#011Loss: 0.231123\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [30720/60000 (51%)]#011Loss: 0.016486\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [35840/60000 (59%)]#011Loss: 0.053288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [40960/60000 (68%)]#011Loss: 0.077070\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [46080/60000 (76%)]#011Loss: 0.016482\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [51200/60000 (85%)]#011Loss: 0.047106\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 4 [56320/60000 (93%)]#011Loss: 0.108830\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0422, Accuracy: 9851/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [0/60000 (0%)]#011Loss: 0.072581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [5120/60000 (8%)]#011Loss: 0.095309\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [10240/60000 (17%)]#011Loss: 0.174521\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [15360/60000 (25%)]#011Loss: 0.141921\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [20480/60000 (34%)]#011Loss: 0.137397\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [25600/60000 (42%)]#011Loss: 0.058034\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [30720/60000 (51%)]#011Loss: 0.028058\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [35840/60000 (59%)]#011Loss: 0.019999\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [40960/60000 (68%)]#011Loss: 0.049779\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [46080/60000 (76%)]#011Loss: 0.039430\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [51200/60000 (85%)]#011Loss: 0.166606\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 5 [56320/60000 (93%)]#011Loss: 0.122117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0400, Accuracy: 9856/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [0/60000 (0%)]#011Loss: 0.063914\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [5120/60000 (8%)]#011Loss: 0.232973\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [10240/60000 (17%)]#011Loss: 0.048393\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [15360/60000 (25%)]#011Loss: 0.111346\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [20480/60000 (34%)]#011Loss: 0.108140\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [25600/60000 (42%)]#011Loss: 0.237901\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [30720/60000 (51%)]#011Loss: 0.012111\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [35840/60000 (59%)]#011Loss: 0.020469\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [40960/60000 (68%)]#011Loss: 0.075157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [46080/60000 (76%)]#011Loss: 0.008395\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [51200/60000 (85%)]#011Loss: 0.028842\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 6 [56320/60000 (93%)]#011Loss: 0.048544\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0388, Accuracy: 9864/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [0/60000 (0%)]#011Loss: 0.044121\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [5120/60000 (8%)]#011Loss: 0.088963\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [10240/60000 (17%)]#011Loss: 0.092076\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [15360/60000 (25%)]#011Loss: 0.043862\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [20480/60000 (34%)]#011Loss: 0.181432\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [25600/60000 (42%)]#011Loss: 0.153395\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [30720/60000 (51%)]#011Loss: 0.013489\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [35840/60000 (59%)]#011Loss: 0.025719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [40960/60000 (68%)]#011Loss: 0.055396\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [46080/60000 (76%)]#011Loss: 0.014623\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [51200/60000 (85%)]#011Loss: 0.056832\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 7 [56320/60000 (93%)]#011Loss: 0.043659\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0381, Accuracy: 9862/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [0/60000 (0%)]#011Loss: 0.021353\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [5120/60000 (8%)]#011Loss: 0.142280\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [10240/60000 (17%)]#011Loss: 0.093338\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [15360/60000 (25%)]#011Loss: 0.120063\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [20480/60000 (34%)]#011Loss: 0.119449\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [25600/60000 (42%)]#011Loss: 0.062314\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [30720/60000 (51%)]#011Loss: 0.033296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [35840/60000 (59%)]#011Loss: 0.020845\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [40960/60000 (68%)]#011Loss: 0.011056\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [46080/60000 (76%)]#011Loss: 0.059486\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [51200/60000 (85%)]#011Loss: 0.099007\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 8 [56320/60000 (93%)]#011Loss: 0.029684\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0369, Accuracy: 9871/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [0/60000 (0%)]#011Loss: 0.021011\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [5120/60000 (8%)]#011Loss: 0.209065\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [10240/60000 (17%)]#011Loss: 0.057607\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [15360/60000 (25%)]#011Loss: 0.069252\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [20480/60000 (34%)]#011Loss: 0.092425\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [25600/60000 (42%)]#011Loss: 0.154039\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [30720/60000 (51%)]#011Loss: 0.020367\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [35840/60000 (59%)]#011Loss: 0.021369\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [40960/60000 (68%)]#011Loss: 0.064061\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [46080/60000 (76%)]#011Loss: 0.030321\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [51200/60000 (85%)]#011Loss: 0.032321\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 9 [56320/60000 (93%)]#011Loss: 0.022207\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0371, Accuracy: 9876/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [0/60000 (0%)]#011Loss: 0.089937\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [5120/60000 (8%)]#011Loss: 0.237252\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [10240/60000 (17%)]#011Loss: 0.040863\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [15360/60000 (25%)]#011Loss: 0.064780\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [20480/60000 (34%)]#011Loss: 0.121557\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [25600/60000 (42%)]#011Loss: 0.111711\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [30720/60000 (51%)]#011Loss: 0.033959\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [35840/60000 (59%)]#011Loss: 0.025474\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [40960/60000 (68%)]#011Loss: 0.150465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [46080/60000 (76%)]#011Loss: 0.085511\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [51200/60000 (85%)]#011Loss: 0.014763\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 10 [56320/60000 (93%)]#011Loss: 0.097404\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0376, Accuracy: 9871/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [0/60000 (0%)]#011Loss: 0.020856\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [5120/60000 (8%)]#011Loss: 0.068525\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [10240/60000 (17%)]#011Loss: 0.034284\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [15360/60000 (25%)]#011Loss: 0.166763\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [20480/60000 (34%)]#011Loss: 0.098335\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [25600/60000 (42%)]#011Loss: 0.090429\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [30720/60000 (51%)]#011Loss: 0.005455\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [35840/60000 (59%)]#011Loss: 0.010823\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [40960/60000 (68%)]#011Loss: 0.030576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [46080/60000 (76%)]#011Loss: 0.030274\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [51200/60000 (85%)]#011Loss: 0.052562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 11 [56320/60000 (93%)]#011Loss: 0.048682\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0369, Accuracy: 9872/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [0/60000 (0%)]#011Loss: 0.013627\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [5120/60000 (8%)]#011Loss: 0.082707\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [10240/60000 (17%)]#011Loss: 0.122726\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [15360/60000 (25%)]#011Loss: 0.200376\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [20480/60000 (34%)]#011Loss: 0.074628\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [25600/60000 (42%)]#011Loss: 0.032664\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [30720/60000 (51%)]#011Loss: 0.018810\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [35840/60000 (59%)]#011Loss: 0.064389\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [40960/60000 (68%)]#011Loss: 0.099955\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [46080/60000 (76%)]#011Loss: 0.026769\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [51200/60000 (85%)]#011Loss: 0.083631\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 12 [56320/60000 (93%)]#011Loss: 0.023423\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0368, Accuracy: 9871/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [0/60000 (0%)]#011Loss: 0.040108\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [5120/60000 (8%)]#011Loss: 0.075346\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [10240/60000 (17%)]#011Loss: 0.034861\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [15360/60000 (25%)]#011Loss: 0.107656\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [20480/60000 (34%)]#011Loss: 0.035862\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [25600/60000 (42%)]#011Loss: 0.063212\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [30720/60000 (51%)]#011Loss: 0.014603\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [35840/60000 (59%)]#011Loss: 0.010819\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [40960/60000 (68%)]#011Loss: 0.029633\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [46080/60000 (76%)]#011Loss: 0.019887\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [51200/60000 (85%)]#011Loss: 0.052000\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 13 [56320/60000 (93%)]#011Loss: 0.026606\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0368, Accuracy: 9874/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [0/60000 (0%)]#011Loss: 0.038551\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [5120/60000 (8%)]#011Loss: 0.040057\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [10240/60000 (17%)]#011Loss: 0.007527\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [15360/60000 (25%)]#011Loss: 0.183121\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [20480/60000 (34%)]#011Loss: 0.022059\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [25600/60000 (42%)]#011Loss: 0.098744\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [30720/60000 (51%)]#011Loss: 0.011259\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [35840/60000 (59%)]#011Loss: 0.021588\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [40960/60000 (68%)]#011Loss: 0.024824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [46080/60000 (76%)]#011Loss: 0.026038\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [51200/60000 (85%)]#011Loss: 0.018138\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Train Epoch: 14 [56320/60000 (93%)]#011Loss: 0.011856\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Test set: Average loss: 0.0367, Accuracy: 9873/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Saving the model...\u001b[0m\n",
      "\u001b[34m2021-01-18 04:56:23,295 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2021-01-18 04:56:23,295 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[35m2021-01-18 04:56:53,325 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2021-01-18 04:56:53,326 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-01-18 04:57:06 Uploading - Uploading generated training model\n",
      "2021-01-18 04:57:06 Completed - Training job completed\n",
      "Training seconds: 598\n",
      "Billable seconds: 598\n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now that you have a trained model, you can deploy an endpoint to host the model. After you deploy the endpoint, you can then test it with inference requests. The following cell will store the model_data variable to be used with the inference notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = estimator.model_data\n",
    "print(\"Storing {} as model_data\".format(model_data))\n",
    "%store model_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
